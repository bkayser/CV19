---
title: "Cleaning COVID-19 Data from Johns Hopkins"
author: "Bill Kayser"
output:
  html_notebook: 
    fig_height: 6
    fig_width: 12
    toc: yes
  html_document: default
  pdf_document: 
    fig_height: 4
    fig_width: 7
    toc: yes
echo: TRUE

---

Initialize the Notebook loading the following required libraries. 

```{r results='hide', message=F}
library(tidyverse)
library(scales)
theme_set(theme_light())
source('utils.R')
```


<style type="text/css">
.table {
    width: inherit;
    max-width: 100%;
    margin-bottom: 20px;
}
.math.display {
  font-size: 28px;
}
</style>

# Load Datasets

We are pulling in data from the github repo of the 2019 Novel Coronavirus Visual Dashboard operated by the Johns Hopkins University Center for Systems Science and Engineering, as well as world population data from wpp2019 and US Census information on county populations.

### COVID-19 Data

Let's update the CV data directly from the Johns Hopkins git repo.  The first thing to do is check for any daily updates by updating the git submodule:

```{r}
system('git submodule update --remote COVID-19')
```

Load the timeseries data.  We'll need to convert the table from a wide format where the time series is in columns to a narrow format where each observation is a single datapoint for a day.

### Load Timeseries Data

```{r, echo=T}
cases <- read_and_clean('COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_US.csv')
deaths <- read_and_clean('COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_US.csv')
countries.cases <- read_and_clean('COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv')
countries.deaths <- read_and_clean('COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv')
```

### Load Census Data

This is how you could get data directly using the US Census bureau APIs but the data appears to be too fine grained.  We can use this later if we need more detailed census information.

```r
get_estimates(product="population", key=Sys.getenv('CENSUS_KEY'))
```

For now I'm just going to use some data I picked up off the census web site in the form of 2019 population estimates by county, and a very old file with square miles for all but about 25 counties.

```{r}
regions <- c('Northeast', 'Midwest', 'South', 'West')
divisions <- c('N Atlantic', 'Mid Atlantic', 'E North Ctrl', 'W North Ctrl', 'S Atlantic', 'E South Ctrl', 'W South Dtrl', 'Mountain', 'Pacific')

geographic_data <- prep_geographic_data(read.csv('data/county_area.csv', skip=7)) 

population_data <- read.csv('https://www2.census.gov/programs-surveys/popest/datasets/2010-2019/counties/totals/co-est2019-alldata.csv') %>% 
  mutate(Region = as.factor(regions[REGION]),
         Division = as.factor(divisions[DIVISION]),
         FIPS=as.integer(str_c(STATE,sprintf('%0.3i', COUNTY)))) %>%
  left_join(geographic_data, by=c(STNAME='State', CTYNAME='County')) %>%
  select(Region,
         State=STNAME,
         Division,
         FIPS,
         CountyCode=COUNTY,
         CTYNAME,
         Population=POPESTIMATE2019,
         Annual.Deaths=DEATHS2019, 
         Area) %>%
  mutate(Population.Density = round(Population / Area, 3)) %>%
   as_tibble()

counties <- filter(population_data, CountyCode > 0) %>% select(-State, -CTYNAME)
states <- filter(population_data, CountyCode == 0) %>% select(-CountyCode)
```

### Load CovidTracking data

This site has an aggregation of data about testing.  It's pretty messy data but we can join what there is to state level historical data.

```{r}
state_abbreviations <- read.csv('data/state_abbrev.csv') %>% select(State, State.Code=Code)
covid.testing <- read.csv('https://covidtracking.com/api/v1/states/daily.csv') %>% 
  as_tibble() %>%
  left_join(state_abbreviations, by=c(state='State.Code')) %>%
  rename(State.Code=state, Date=date) %>%
  mutate(Date = as.Date(as.POSIXct(strptime(as.character(Date), format='%Y%m%d'))))
```

# Prepare Data

### Join Tables

Start combining tables with external data.  Also invokes `calculate_differentials()` which adds new variables which are the single day and 3 day changes to Cases and Deaths, in addition to a Growth3 variable which is the average daily growth rate of Cases and Deaths over a three day period.

Join the US confirmed cases to deaths and census population data.  Create a single table, `cvdata.us`.

```{r}
cvdata.us <- left_join(cases, 
                       select(deaths, Key, Date, Count),
                       by=c('Key', 'Date')) %>%
  rename(Cases = Count.x,
         Deaths = Count.y) %>%
  left_join(counties, by='FIPS') %>% 
  left_join(state_abbreviations, by='State') %>% 
  filter(!is.na(Region)) %>%
  mutate(State = as.factor(State), 
         County = as.factor(County)) %>%
  calculate_differentials(c('Cases', 'Deaths'))
```

Join the cases and deaths for country data into a single table, `cvdata.i18n`.

```{r}
populations <- read.csv('data/population.csv', skip = 3, stringsAsFactors = F) %>% select(Country = Country.Name, Population = X2018)
populations[populations$Country == 'Korea, Rep.', 'Country'] = 'Korea, South'
populations[populations$Country == 'United States', 'Country'] = 'US'
populations[populations$Country == 'Russian Federation', 'Country'] = 'Russia'
populations[populations$Country == 'Iran, Islamic Rep.', 'Country'] = 'Iran'
populations[populations$Country == 'Taiwan*', 'Country'] = 'Taiwan'
populations[nrow(populations)+1, ] <- list('China, Hubei', 58.5e6) # 2015 National bureau of stats, China

cvdata.i18n <- 
  countries.cases %>%
  left_join(populations, by='Country') %>%
  left_join(select(countries.deaths, Key, Date, Deaths=Count),
            by=c('Key', 'Date')) %>%
  rename(Cases=Count) %>% 
  calculate_differentials(c('Cases', 'Deaths'))
  
```

### Derive Additional Tables

Group data by state and save into table `cvdata.us.by_state`.

```{r, message=F}
cvdata.us.by_state <- cvdata.us %>%
  group_by(State, Date) %>%
  summarize(Cases = sum(Cases),
            Key = first(State),
            Deaths = sum(Deaths))%>%
  ungroup(State, Date) %>%
  left_join(states, by=c('State')) %>% mutate(State = as.factor(State)) %>%
  filter(!is.na(Region))  %>%
  # Join with the testing data
  left_join(covid.testing, by=c('State', 'Date')) %>%
  select(-hash, -dateChecked, -fips, -CTYNAME) %>% 
  calculate_differentials(c('Cases', 'Deaths')) %>%
  mutate(State.Code = fct_inorder(as.factor(State.Code)),
         State = fct_inorder(as.factor(State)),
         Infection.Rate = Cases.Diff * 1000000 / Population,
         Death.Rate = Deaths.Diff * 1000000 / Population)
```

Create a single timeseries table just for Italy called `italy`.

```{r}
italy <- cvdata.i18n %>%
  filter(Country == 'Italy') %>%
  select(-Key, -Lat, -Long, -Country) 

```
# Save the Data

```{r echo=T}
saveRDS(cvdata.us, 'data/cvdata.us.RDS')
saveRDS(cvdata.us.by_state, 'data/cvdata.us.by_state.RDS')
saveRDS(cvdata.i18n, 'data/cvdata.i18n.RDS')
```

