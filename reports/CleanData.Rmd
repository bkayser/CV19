---
title: "Cleaning COVID-19 Data from Johns Hopkins"
author: "Bill Kayser"
output:
  html_notebook: 
    fig_height: 6
    fig_width: 12
    toc: yes
  html_document: default
  pdf_document: 
    fig_height: 4
    fig_width: 7
    toc: yes
echo: TRUE

---

Initialize the Notebook loading the following required libraries. 

```{r results='hide', message=F}
library(tidyverse)
library(scales)
old_theme <- theme_set(theme_light())
source('../utils/utils.R')
```


<style type="text/css">
.table {
    width: inherit;
    max-width: 100%;
    margin-bottom: 20px;
}
.math.display {
  font-size: 28px;
}
</style>

# Load Datasets

We are pulling in data from the github repo of the 2019 Novel Coronavirus Visual Dashboard operated by the Johns Hopkins University Center for Systems Science and Engineering, as well as world population data from wpp2019 and US Census information on county populations.

### COVID-19 Data

Let's update the CV data directly from the Johns Hopkins git repo.  The first thing to do is check for any daily updates by updating the git submodule:

```{r}
system('git submodule update --remote ../COVID-19')
```

Load the timeseries data.  We'll need to convert the table from a wide format where the time series is in columns to a narrow format where each observation is a single datapoint for a day.

The US data in the Johns Hopkins DB seemed to get stuck with confirmed cases and drifted from other sources so I'm 
using the NY Times for US data and Johns Hopkins for International Data.

### Load International Timeseries Data - Johns Hopkins

```{r}
countries.cases <- read_and_clean('../COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv')
countries.deaths <- read_and_clean('../COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv')
countries.recovered <- read_and_clean('../COVID-19/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv')
```

### Load US Timeseries Data - NY Times

Taken from the raw downloads at https://github.com/nytimes/covid-19-data.

Interactive explorer available [here](https://www.nytimes.com/interactive/2020/us/coronavirus-us-cases.html).

```{r}
raw_county_data <- read.csv('https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv',
                            stringsAsFactors = F) %>%
  select(State = state, 
         FIPS = fips,
         Date = date,
         Cases = cases,
         County = county,
         Deaths = deaths) %>%
  mutate(Key = paste0(County, ", ", State, ", US"),
         Date = ymd(Date)) %>%
  as_tibble()
```

Now we need to pad data with zeros.

```{r}
county_data <- expand_grid(Date = unique(raw_county_data$Date),
                          Key = unique(raw_county_data$Key)) %>%
  left_join(unique(select(raw_county_data, Key, County, State, FIPS)),
            by='Key') %>%
  left_join(raw_county_data, by=c('Key', 'Date', 'County', 'State', 'FIPS')) %>%
  mutate(Country = 'US',
         Lat = 0,
         Long = 0,
         Cases = ifelse(is.na(Cases), 0, Cases),
         Deaths = ifelse(is.na(Deaths), 0, Deaths)) %>%
  arrange(State, Key, Date)
rm(raw_county_data)
```


### Load Census Data

This is how you could get data directly using the US Census bureau APIs but the data appears to be too fine grained.  We can use this later if we need more detailed census information.

```r
get_estimates(product="population", key=Sys.getenv('CENSUS_KEY'))
```

For now I'm just going to use some data I picked up off the census web site in the form of 2019 population estimates by county, and a very old file with square miles for all but about 25 counties.

```{r}
regions <- c('Northeast', 'Midwest', 'South', 'West')
divisions <- c('N Atlantic', 'Mid Atlantic', 'E North Ctrl', 'W North Ctrl', 'S Atlantic', 'E South Ctrl', 'W South Dtrl', 'Mountain', 'Pacific')

population_data <- read.csv('https://www2.census.gov/programs-surveys/popest/datasets/2010-2019/counties/totals/co-est2019-alldata.csv') %>% 
  mutate(Region = as.factor(regions[REGION]),
         Division = as.factor(divisions[DIVISION]),
         FIPS=as.integer(str_c(STATE,sprintf('%0.3i', COUNTY)))) %>%
  left_join(get_geographic_data(), by=c(STNAME='State', CTYNAME='County')) %>%
  select(Region,
         State=STNAME,
         Division,
         FIPS,
         CountyCode=COUNTY,
         CTYNAME,
         Population=POPESTIMATE2019,
         Annual.Deaths=DEATHS2019, 
         Area) %>%
  mutate(Population.Density = round(Population / Area, 3)) %>%
  as_tibble()

# Correct some data from NYC: New York County is reported for all of New York City.
nyc <- population_data %>%
  filter(State == 'New York' & (CTYNAME %in% c('Bronx County', 'Kings County', 'Queens County', 'Richmond County', 'New York County'))) %>%
  select(Population, Annual.Deaths, Area) %>%
  colSums()
ny.row <- which(population_data$CTYNAME == 'New York County')
population_data[ny.row, 'Population'] <- nyc['Population']
population_data[ny.row, 'Annual.Deaths'] <- nyc['Annual.Deaths']
population_data[ny.row, 'Area'] <- nyc['Area']
FIPS.nyc <- population_data[ny.row,]$FIPS
population_data[ny.row, 'CTYNAME'] <- 'New York City'  # This is needed only for NYT sourced cases

# Remove other boroughs since we don't get data for them.
population_data <- filter(population_data, 
                          State != 'New York' | !(CTYNAME %in% c('Bronx County', 'Kings County', 'Queens County', 'Richmond County'))) 

counties <- filter(population_data, CountyCode > 0) %>% select(-State, -CTYNAME)
states <- filter(population_data, CountyCode == 0) %>% select(-CountyCode)
rm(regions, divisions, population_data, nyc, ny.row)

```

### Load CovidTracking data

This site has an aggregation of data about testing.  It's pretty messy data but we can join what there is to state level historical data.

```{r}

covid.testing <- read.csv('https://covidtracking.com/api/v1/states/daily.csv') %>% 
  as_tibble() %>%
  rename(State.Code=state, Date=date) %>%
  select(-positiveIncrease,         # Remove deprecated fields
         -total,
         -totalTestResults,
         -totalTestResultsIncrease,
         -posNeg,
         -negativeIncrease,
         -hospitalizedIncrease,
         -hospitalized) %>%
  mutate(Date = as.Date(as.POSIXct(strptime(as.character(Date), format='%Y%m%d'))))
```

# Prepare Data

### Join Tables

Start combining tables with external data.  Also invokes `calculate_differentials()` which adds new variables which are the single day and 3 day changes to Cases and Deaths, in addition to a Growth3 variable which is the average daily growth rate of Cases and Deaths over a three day period.

Join in information on the status of states.  Information scraped from a Washington Post article on the status of each state.

```{r}
states.summary <- readRDS('../data/states.status.RDS')
```

The cases and deaths data provided for the five counties of New York City is aggregated into a single entity called "New York City" with no FIPS.

For purposes of joining data, I'm going to use the New York County FIPS for "New York City".

```{r}
county_data[county_data$County == 'New York City', 'FIPS'] <- FIPS.nyc
```


Join the US confirmed cases to deaths and census population data.  Create a single table, `cvdata.us`.

```{r}
cvdata.us <- county_data %>%
  left_join(counties, by='FIPS') %>% 
  left_join(states.summary, by=c('State')) %>%
  filter(!is.na(Region)) %>%
  mutate(State = as.factor(State), 
         County = as.factor(County)) %>%
  calculate_differentials(c('Cases', 'Deaths'))
rm(counties, county_data)
```

Join the cases and deaths for country data into a single table, `cvdata.i18n`.

```{r}
populations <- read.csv('../data/population.csv', skip = 3, stringsAsFactors = F) %>% select(Country = Country.Name, Population = X2018)
populations[populations$Country == 'Korea, Rep.', 'Country'] = 'Korea, South'
populations[populations$Country == 'United States', 'Country'] = 'US'
populations[populations$Country == 'Russian Federation', 'Country'] = 'Russia'
populations[populations$Country == 'Iran, Islamic Rep.', 'Country'] = 'Iran'
populations[populations$Country == 'Taiwan*', 'Country'] = 'Taiwan'
populations[nrow(populations)+1, ] <- list('China, Hubei', 58.5e6) # 2015 National bureau of stats, China

cvdata.i18n <- 
  countries.cases %>%
  left_join(populations, by='Country') %>%
  left_join(select(countries.deaths, Key, Date, Deaths=Count),
            by=c('Key', 'Date')) %>%
  rename(Cases=Count) %>% 
  left_join(select(countries.recovered, -Lat, -Long, -Country), by=c('Key', 'Date')) %>%
  rename(recovered=Count) %>%
  add_estimated_recoveries() %>%
  calculate_differentials(c('Cases', 'Deaths'))
rm(populations, countries.cases, countries.recovered, countries.deaths)
```


### Derive Additional Tables

Group data by state and save into table `cvdata.us.by_state`.

```{r, message=F}
cvdata.us.by_state <- cvdata.us %>%
  group_by(State, State.Code, Date) %>%
  summarize(Cases = sum(Cases),
            Key = first(State),
            Deaths = sum(Deaths),
            Lat = last(Lat),
            Long = last(Long))%>%
  ungroup(State, Date) %>%
  left_join(states, by=c('State')) %>%
  mutate(State = as.factor(State)) %>%
  filter(!is.na(Region)) %>%
  left_join(covid.testing, by=c('State.Code', 'Date')) %>%
  select(-hash, -dateChecked, -fips, -CTYNAME) %>% 
  calculate_differentials(c('Cases', 'Deaths')) %>%
  mutate(State.Code = fct_inorder(as.factor(State.Code)),
         State = fct_inorder(as.factor(State)),
         Infection.Rate = Cases.Diff * 1000000 / Population,
         Death.Rate = Deaths.Diff * 1000000 / Population,
         total = positive + negative,
         Testing.Rate = total / Population,
         Testing.Positive.Rate = positive / total) %>%
  add_estimated_recoveries() %>%
  left_join(states.summary, by=c('State', 'State.Code')) %>%
  select(Key, State, State.Code, Region, Division, Date, starts_with('Cases'), starts_with('Deaths'), contains('Recovered'), matches('^[A-Z]', ignore.case=F), -FIPS, everything())
rm(states)

```


### Estimate Recoveries

From **Report of the WHO-China Joint Mission on Coronavirus Disease 2019 (COVID-19)**

    Using available preliminary data, the median time from onset to clinical recovery for mild
    cases is approximately 2 weeks and is 3-6 weeks for patients with severe or critical disease.
    Preliminary data suggests that the time period from onset to the development of severe
    disease, including hypoxia, is 1 week. Among patients who have died, the time from
    symptom onset to outcome ranges from 2-8 weeks. 

https://www.who.int/docs/default-source/coronaviruse/who-china-joint-mission-on-covid-19-final-report.pdf

Let's pick a distribution to estimate the recovery probability.

There's not much to tell from the research.  I will assume most of the confirmed cases are not mild.  Normally
mild cases are about 80% but I think our testing is biased toward people with severe symptoms.  

I'll pick a gamma distribution with a mean of 4 weeks, a wide shape, and an offset of 10 days so there are no recoveries earlier than that.

```{r}

mean <- 28
start <- 6
scale  <- 6
shape <- (mean - start) / scale
x <- 1:60

quantiles <- pgamma(x-start, scale = scale, shape = shape)
probabilities <- quantiles - c(0, quantiles[1:(length(quantiles)-1)]) 
qplot(x, probabilities, geom='line') + geom_vline(xintercept=mean)
rm(mean, start, scale, shape, x)

```

Now let's go back over the confirmed cases and project their recoveries based on the normal dist.

```{r fig.width=6, fig.height=3}
gather(cvdata.us.by_state, key='Measure', value='Recoveries', 'Recovered', 'Est.Recovered', 'Cases') %>%
  filter(!is.na(Recoveries) & State %in% c('Arizona', 'Texas', 'District of Columbia', 'Kentucky', 'Oklahoma', 'Arkansas')) %>%
  ggplot() +
  aes(x=Date, y=Recoveries, linetype=Measure, color=State)+
  geom_line() +
  coord_cartesian(xlim = c(mdy('03-25-2020'), today()))+
  facet_wrap('State') +
  scale_y_continuous(labels=comma)
```

```{r fig.width=6, fig.height=5}

gather(cvdata.i18n, key='Measure', value='Recoveries', 'Recovered', 'Est.Recovered', 'Cases') %>%
  filter(Recoveries > 0 & Country %in% c('Australia', 'Hubei - China', 'France', 'Italy', 'Spain', 'US', 'Germany', 'Austria', 'Russia', 'Korea, South')) %>%
ggplot() +
  aes(x=Date, y=Recoveries, linetype=Measure, color=Country)+
  geom_line() +
  coord_cartesian(xlim = c(mdy('02-25-2020'), today())) +
  facet_wrap('Country') +
  scale_y_log10(labels=comma)

```


# Save the Data

```{r echo=T}
saveRDS(cvdata.us, '../data/cvdata.us.RDS')
saveRDS(cvdata.us.by_state, '../data/cvdata.us.by_state.RDS')
saveRDS(cvdata.i18n, '../data/cvdata.i18n.RDS')
```

